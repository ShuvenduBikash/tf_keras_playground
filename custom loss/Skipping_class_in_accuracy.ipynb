{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('treebank')\n",
    " \n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorillard' 'Inc.' ',' 'the' 'unit' 'of' 'New' 'York-based' 'Loews'\n",
      " 'Corp.' 'that' '*T*-2' 'makes' 'Kent' 'cigarettes' ',' 'stopped' 'using'\n",
      " 'crocidolite' 'in' 'its' 'Micronite' 'cigarette' 'filters' 'in' '1956'\n",
      " '.']\n",
      "['NNP' 'NNP' ',' 'DT' 'NN' 'IN' 'JJ' 'JJ' 'NNP' 'NNP' 'WDT' '-NONE-' 'VBZ'\n",
      " 'NNP' 'NNS' ',' 'VBD' 'VBG' 'NN' 'IN' 'PRP$' 'NN' 'NN' 'NNS' 'IN' 'CD'\n",
      " '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    " \n",
    "# Let's see how a sequence looks\n",
    " \n",
    "print(sentences[5])\n",
    "print(sentence_tags[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bangla_processor import *\n",
    "import codecs\n",
    "\n",
    "with codecs.open('data.txt', 'r', 'utf-8') as f:\n",
    "    sentences, sentence_tags =[], [] \n",
    "    for line in f:\n",
    "        sentences.append(word_tokenizer_bangla(line))\n",
    "        tag_line = f.readline()\n",
    "        sentence_tags.append(tag_line.strip().split(' '))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আজ', 'দোকানপাট', 'বন্ধ', 'থাকবে']\n",
      "['ADV', 'Np', 'VB', 'VBf']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(sentence_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, train_tags = sentences, sentence_tags\n",
    " \n",
    "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    " \n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    " \n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14, 23, 26, 8, 12, 7]\n",
      "[4, 29, 10, 34, 1]\n",
      "[15, 3, 10, 15, 14, 9, 9]\n",
      "[13, 9, 15, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    " \n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    " \n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    " \n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "for s in test_tags:\n",
    "    try:\n",
    "        test_tags_y.append([tag2index[t] for t in s])\n",
    "    except:\n",
    "        test_tags_y.append([])\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences_X))\n",
    "print(len(test_sentences_X))\n",
    "print(len(train_tags_y))\n",
    "print(len(test_tags_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)  # 271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 14 23 26  8 12  7]\n",
      "[ 4 29 10 34  1  0  0]\n",
      "[15  3 10 15 14  9  9]\n",
      "[13  9 15 16 18  0  0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 7, 128)            4480      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 7, 512)            788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 7, 19)             9747      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 19)             0         \n",
      "=================================================================\n",
      "Total params: 802,707\n",
      "Trainable params: 802,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 1 samples\n",
      "Epoch 1/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7202 - accuracy: 0.8929 - val_loss: 6.0882 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5463 - accuracy: 0.9107 - val_loss: 5.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5490 - accuracy: 0.8393 - val_loss: 6.4112 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3395 - accuracy: 0.8929 - val_loss: 5.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2697 - accuracy: 0.9643 - val_loss: 5.2919 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1689 - accuracy: 0.9643 - val_loss: 6.3045 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 6.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 6.3624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 6.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 6.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 6.7478 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 6.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 6.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 6.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 6.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 6.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 7.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 7.1188 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 7.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 7.2179 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 7.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 7.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 7.3381 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 7.3785 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 7.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 7.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 7.4889 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 7.5200 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 7.5565 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.5872 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 7.6180 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 7.6493 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 7.6770 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 7.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 7.7314 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 7.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 7.7896 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 7.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 7.8394 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 7.8617 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fdf994f1a50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=1, epochs=40, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "accuracy: 85.71428656578064\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 99.09751977804825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['মা', 'ছবিটা', 'আনতে', 'পারত'], ['মা', 'ছবিটা', 'আনতে', 'পারত'], ['গতকাল', 'ছবিটা', 'দেখনি'], ['ছবিটা', 'না', 'দেখে', 'যাব', 'না'], ['এসব', 'স্কুলে', 'গতকাল', 'উপস্থিত', 'ছিল'], ['ছবিটা', 'ঢাকা', 'ছিল'], ['মুখেও', 'কি', 'ছিল', 'না']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "        \"মা ছবিটা আনতে পারত\".split(),\n",
    "        \"মা ছবিটা আনতে পারত\".split(),\n",
    "        \"গতকাল ছবিটা দেখনি\".split(),\n",
    "        \"ছবিটা না দেখে যাব না\".split(),\n",
    "        \"এসব স্কুলে গতকাল উপস্থিত ছিল\".split(),\n",
    "        \"ছবিটা ঢাকা ছিল\".split(),\n",
    "        \"মুখেও কি ছিল না\".split()\n",
    "]\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6 33  9  0  0  0]\n",
      " [ 2  6 33  9  0  0  0]\n",
      " [29  6 25  0  0  0  0]\n",
      " [ 6  4 23 20  4  0  0]\n",
      " [19 10 29 21 13  0  0]\n",
      " [ 6 27 13  0  0  0  0]\n",
      " [32 28 13  4  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    " \n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 19)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['মা', 'ছবিটা', 'আনতে', 'পারত'], ['মা', 'ছবিটা', 'আনতে', 'পারত'], ['গতকাল', 'ছবিটা', 'দেখনি'], ['ছবিটা', 'না', 'দেখে', 'যাব', 'না'], ['এসব', 'স্কুলে', 'গতকাল', 'উপস্থিত', 'ছিল'], ['ছবিটা', 'ঢাকা', 'ছিল'], ['মুখেও', 'কি', 'ছিল', 'না']]\n",
      "[['PN2s', 'Ns', 'Ns', 'VBint', '-PAD-', '-PAD-', '-PAD-'], ['PN2s', 'Ns', 'Ns', 'VBint', '-PAD-', '-PAD-', '-PAD-'], ['ADV', 'Ns', 'Ns', 'VB2', '-PAD-', '-PAD-', '-PAD-'], ['PN3s', 'Ns', 'Ns', 'VBint', 'VB1', '-PAD-', '-PAD-'], ['PN1', 'Ns', 'Ns', 'ADJ', 'VB2', '-PAD-', '-PAD-'], ['PN1', 'Ns', 'Vf', 'VB1', '-PAD-', '-PAD-', '-PAD-'], ['PN1', 'Ns', 'Vf', 'ADV', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "print(test_samples)\n",
    "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss\n",
    "You probably are fairly acquainted with the PennTreebank tagset by now and you’re probably disappointed with the result. What’s wrong?\n",
    "\n",
    "For most of the sentences, the largest part is “padding tokens”. These are really easy to guess, hence the super high performance. Let’s write a custom accuracy, that ignores the paddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    " \n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 7, 128)            4480      \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 7, 512)            788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 7, 19)             9747      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 19)             0         \n",
      "=================================================================\n",
      "Total params: 802,707\n",
      "Trainable params: 802,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy', ignore_class_accuracy(0)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 1 samples\n",
      "Epoch 1/40\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.9195 - accuracy: 0.2500 - ignore_accuracy: 0.1399 - val_loss: 2.8348 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.5000\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.7880 - accuracy: 0.4107 - ignore_accuracy: 0.2798 - val_loss: 2.6077 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.5000\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4799 - accuracy: 0.3393 - ignore_accuracy: 0.2708 - val_loss: 2.0601 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.3333\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1032 - accuracy: 0.3571 - ignore_accuracy: 0.2688 - val_loss: 2.4264 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8685 - accuracy: 0.4821 - ignore_accuracy: 0.3973 - val_loss: 2.0807 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7244 - accuracy: 0.5000 - ignore_accuracy: 0.4182 - val_loss: 2.3418 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5611 - accuracy: 0.5000 - ignore_accuracy: 0.3765 - val_loss: 2.8617 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4254 - accuracy: 0.4821 - ignore_accuracy: 0.3494 - val_loss: 2.9291 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2821 - accuracy: 0.5000 - ignore_accuracy: 0.4182 - val_loss: 2.9361 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1652 - accuracy: 0.5714 - ignore_accuracy: 0.4890 - val_loss: 3.3304 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0738 - accuracy: 0.6607 - ignore_accuracy: 0.5720 - val_loss: 3.2220 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9579 - accuracy: 0.6429 - ignore_accuracy: 0.5446 - val_loss: 3.6022 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8665 - accuracy: 0.6964 - ignore_accuracy: 0.6479 - val_loss: 3.7199 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7793 - accuracy: 0.7500 - ignore_accuracy: 0.7196 - val_loss: 3.9006 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6843 - accuracy: 0.7500 - ignore_accuracy: 0.6946 - val_loss: 3.9566 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.8214 - ignore_accuracy: 0.8179 - val_loss: 4.1262 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5647 - accuracy: 0.7857 - ignore_accuracy: 0.7571 - val_loss: 4.3950 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4815 - accuracy: 0.8571 - ignore_accuracy: 0.8500 - val_loss: 4.3981 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.9464 - ignore_accuracy: 0.9464 - val_loss: 4.7221 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.9464 - ignore_accuracy: 0.9393 - val_loss: 4.6119 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.8750 - ignore_accuracy: 0.8750 - val_loss: 4.8172 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.2000\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3003 - accuracy: 0.9643 - ignore_accuracy: 0.9438 - val_loss: 4.6803 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4303 - accuracy: 0.8571 - ignore_accuracy: 0.8196 - val_loss: 4.2879 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2832 - accuracy: 0.9107 - ignore_accuracy: 0.8830 - val_loss: 4.5411 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2461 - accuracy: 0.9821 - ignore_accuracy: 1.0000 - val_loss: 4.4432 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2041 - accuracy: 0.9643 - ignore_accuracy: 0.9643 - val_loss: 4.4071 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.3703 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1512 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.5286 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.9821 - ignore_accuracy: 0.9821 - val_loss: 4.7029 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.2000\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1334 - accuracy: 0.9821 - ignore_accuracy: 0.9792 - val_loss: 4.6135 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1051 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.6881 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0954 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.7780 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0880 - accuracy: 0.9821 - ignore_accuracy: 0.9821 - val_loss: 4.8035 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0826 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.8541 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.9300 - val_accuracy: 0.4286 - val_ignore_accuracy: 0.2000\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0620 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.9241 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0563 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.9570 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0530 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.9632 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0483 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 4.9809 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0454 - accuracy: 1.0000 - ignore_accuracy: 1.0000 - val_loss: 5.0047 - val_accuracy: 0.5714 - val_ignore_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fdf9947b210>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=1, epochs=40, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_tf",
   "language": "python",
   "name": "torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
